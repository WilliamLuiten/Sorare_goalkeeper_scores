{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166b774-2987-4cb9-b342-ab27de1ae2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.chdir(\"\")   #Set working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e1ddd-48dd-4c18-b4f4-0d5d6bdd3b36",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24d9e9-ad20-40bb-a769-a9efcdf9aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from sorare and players\n",
    "eredivisie_games= pd.read_csv(\"./eredivisie_player_game_info.csv\")\n",
    "eredivisie_players= pd.read_csv(\"./eredivisie_player_info.csv\")\n",
    "pl_games= pd.read_csv(\"./pl_player_game_info.csv\")\n",
    "pl_players= pd.read_csv(\"./pl_player_info.csv\")\n",
    "\n",
    "#Data from Rapid API\n",
    "home_df= pd.read_csv(\"./home_df.csv\")\n",
    "away_df= pd.read_csv(\"./home_df.csv\")\n",
    "\n",
    "#Fixtures data 2024/204 and standing in 2023\n",
    "games_dates= pd.read_csv(\"./games_dates.csv\")\n",
    "standing_df= pd.read_csv(\"./standing_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8853381-765b-4771-b414-9ab5991bd047",
   "metadata": {},
   "source": [
    "# Calculate elo-ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfdc88-d6aa-491d-b73d-0d6510a1288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we caluclate the ELO, we need to give a value to winning (1), draw (0.5) or loss (0)\n",
    "values = [1, 0.5, 0]\n",
    "\n",
    "#Define the condition\n",
    "home_conditions = [\n",
    "    games_dates['homegoals'] > games_dates['awaygoals'],\n",
    "    games_dates['homegoals'] == games_dates['awaygoals'],\n",
    "    games_dates['homegoals'] < games_dates['awaygoals']\n",
    "]\n",
    "\n",
    "away_conditions = [\n",
    "    games_dates['homegoals'] < games_dates['awaygoals'],\n",
    "    games_dates['homegoals'] == games_dates['awaygoals'],\n",
    "    games_dates['homegoals'] > games_dates['awaygoals']\n",
    "]\n",
    "\n",
    "#Determine the result scores\n",
    "games_dates['home_result'] = np.select(home_conditions, values)\n",
    "games_dates['away_result'] = np.select(away_conditions, values)\n",
    "games_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31d2cb-b5b2-4d73-bae0-3c790ad335e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters\n",
    "#100 for home advantage and 16 for sensitivity \n",
    "bonus=100 \n",
    "sensitivity=16\n",
    "\n",
    "#calculate rating based on standing\n",
    "standing_df['elo_value']=1700 - (((standing_df['rank'] - 1) * (1700 - 1300)) / (max(standing_df['rank']) - 1))\n",
    "\n",
    "# Create df with all teams\n",
    "teams = pd.unique(games_dates[['hometeam', 'awayteam']].values.ravel())\n",
    "\n",
    "elo_df = pd.DataFrame({\n",
    "    'teamname': teams,\n",
    "    })\n",
    "\n",
    "#merge standing and team df together and imputate missing values with lowest rating\n",
    "elo_df = pd.merge(elo_df, standing_df[['teamname', 'elo_value']], how=\"left\", on=[\"teamname\"])\n",
    "elo_df['elo_value']=elo_df['elo_value'].fillna(min(elo_df['elo_value']))\n",
    "\n",
    "elo_data = []\n",
    "\n",
    "#Sort date values (we again assume one game per day per club.\n",
    "games_dates = games_dates.sort_values(by='Date').copy()\n",
    "\n",
    "for _, row in games_dates.iterrows():\n",
    "    home = row['hometeam']\n",
    "    away = row['awayteam']\n",
    "    home_goals = row['homegoals']\n",
    "    away_goals = row['awaygoals']\n",
    "    home_result = row['home_result'] \n",
    "    away_result = row['away_result']  \n",
    "\n",
    "        # Get current ratings\n",
    "    elo_home = elo_df.loc[elo_df['teamname'] == home, 'elo_value'].iloc[0]\n",
    "    elo_away = elo_df.loc[elo_df['teamname'] == away, 'elo_value'].iloc[0]\n",
    "\n",
    "        # Expected outcomes\n",
    "    E_home = 1 / (1 + 10 ** ((elo_away - (elo_home + bonus)) / 400))\n",
    "    E_away = 1 - E_home\n",
    "\n",
    "    # Goal difference adjustment (optional)\n",
    "    goal_diff = abs(home_goals - away_goals) #(we take absolute because the result is also minus)\n",
    "    multiplier = min(4, goal_diff + 0.5)  # min cap 4, max cap 4 \n",
    "\n",
    "    #update elo rating, \n",
    "    #To reward big wins, you can scale the rating change by a goal difference multiplier, add a 0.5 to avoid getting a 0* everything.\n",
    "    new_elo_home = elo_home + (sensitivity * multiplier * (home_result - E_home))\n",
    "    new_elo_away = elo_away + (sensitivity * multiplier * (away_result - E_away))\n",
    "\n",
    "        # Save back\n",
    "    elo_df.loc[elo_df['teamname'] == home, 'elo_value'] = new_elo_home\n",
    "    elo_df.loc[elo_df['teamname'] == away, 'elo_value'] = new_elo_away\n",
    "\n",
    "    # Save data for record\n",
    "    row_out = row.copy()\n",
    "    row_out['elo_value_home'] = elo_home\n",
    "    row_out['elo_value_away'] = elo_away\n",
    "    elo_data.append(row_out)\n",
    "\n",
    "#Save the results into a dataframe\n",
    "elo_scores_data = pd.DataFrame(elo_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9496ba8-18b5-454b-8655-5a4fdde4b523",
   "metadata": {},
   "source": [
    "# Clean and modify the fixture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02abc0-42b5-44fd-8180-6d97aa9debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Keep only columns that we need\n",
    "away_df_v2 = away_df[['teamname', 'fixture']]\n",
    "home_df_v2 = home_df[['teamname', 'fixture']]\n",
    "\n",
    "#Fixture is an object, and int in games df, thus change type\n",
    "away_df_v2['fixture'] = pd.to_numeric(away_df_v2['fixture'],errors = 'coerce')\n",
    "home_df_v2['fixture'] = pd.to_numeric(home_df_v2['fixture'],errors = 'coerce')\n",
    "\n",
    "#Merge date info and elo values\n",
    "away_df_v2 = pd.merge(away_df_v2, elo_scores_data[['fixture', 'Date', 'elo_value_away', 'awaygoals']], how=\"left\", on=[\"fixture\"])\n",
    "away_df_v2 = away_df_v2.rename(columns={\"awaygoals\": \"goals\"})\n",
    "\n",
    "#Also for the home teams\n",
    "home_df_v2 = pd.merge(home_df_v2, elo_scores_data[['fixture', 'Date', 'elo_value_home', 'homegoals']], how=\"left\", on=[\"fixture\"])\n",
    "home_df_v2 = home_df_v2.rename(columns={\"homegoals\": \"goals\"})\n",
    "\n",
    "#Now we create values that define the opponent scores\n",
    "away_df_temp = away_df_v2.drop(columns=['Date'])\n",
    "#Rename to understand that these are the opponent columns\n",
    "away_df_temp = away_df_temp.add_prefix('opponent_')\n",
    "#DO not change the fixture name, since it is the merge var\n",
    "away_df_temp = away_df_temp.rename(columns={\"opponent_fixture\": \"fixture\"})\n",
    "#Merge\n",
    "New_home_df_v3 = pd.merge(home_df_v2, away_df_temp, how=\"left\", on=[\"fixture\"])\n",
    "#Some more renames\n",
    "New_home_df_v3 = New_home_df_v3.rename(columns={\"elo_value_home\": \"elo_value\", \"opponent_elo_value_away\": \"opponent_elo_value\"})\n",
    "New_home_df_v3['place']=\"home\"\n",
    "\n",
    "#Same for the away df\n",
    "home_df_temp = home_df_v2.drop(columns=['Date'])\n",
    "home_df_temp = home_df_temp.add_prefix('opponent_')\n",
    "home_df_temp = home_df_temp.rename(columns={\"opponent_fixture\": \"fixture\"})\n",
    "New_awaydf_v3 = pd.merge(away_df_v2, home_df_temp, how=\"left\", on=[\"fixture\"])\n",
    "New_awaydf_v3 = New_awaydf_v3.rename(columns={\"elo_value_away\": \"elo_value\", \"opponent_elo_value_home\": \"opponent_elo_value\"})\n",
    "New_awaydf_v3['place']=\"away\"\n",
    "\n",
    "#Concat both dataframes together\n",
    "total_df = pd.concat([New_home_df_v3, New_awaydf_v3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16599933-7fc8-434b-a57c-71f8576c07c7",
   "metadata": {},
   "source": [
    "# Merge the multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6270ff-cd68-4a0e-943c-3a672141c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine player and game info\n",
    "eredivisie = pd.merge(eredivisie_games, eredivisie_players, how=\"left\", on=[\"slug\"])\n",
    "pl= pd.merge(pl_games, pl_players, how=\"left\", on=[\"slug\"])\n",
    "#combine eredivisie and premier league data\n",
    "sorare_data = pd.concat([pl, eredivisie], ignore_index=True)\n",
    "#Only players who played more than 60 minutes\n",
    "sorare_data = sorare_data[(sorare_data[\"minsPlayed\"]>60)]\n",
    "\n",
    "#make date variables datetime\n",
    "sorare_data['Date'] =pd.to_datetime(sorare_data['Date']).dt.date\n",
    "total_df['Date'] =pd.to_datetime(total_df['Date']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec86f3-9538-4670-94da-cf2cbc0be125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to merge two datatables from two sources. Both sources label the teamnames differently, thus rename\n",
    "sorare_data.loc[sorare_data['teamname'] =='Sparta Rotterdam', 'teamname'] = 'Sparta Rotterdam'\n",
    "sorare_data.loc[sorare_data['teamname'] =='RKC Waalwijk', 'teamname'] = 'Waalwijk'\t \n",
    "sorare_data.loc[sorare_data['teamname'] =='FC Utrecht', 'teamname'] = 'Utrecht'\n",
    "sorare_data.loc[sorare_data['teamname'] =='FC Groningen', 'teamname'] = 'Groningen'\n",
    "sorare_data.loc[sorare_data['teamname'] =='PEC Zwolle', 'teamname'] = 'PEC Zwolle'\n",
    "sorare_data.loc[sorare_data['teamname'] =='NAC Breda', 'teamname'] = 'NAC Breda'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Almere City FC', 'teamname'] = 'Almere City FC'\n",
    "sorare_data.loc[sorare_data['teamname'] =='sc Heerenveen', 'teamname'] = 'Heerenveen'\n",
    "sorare_data.loc[sorare_data['teamname'] =='FC Twente', 'teamname'] = 'Twente'\n",
    "sorare_data.loc[sorare_data['teamname'] =='AZ', 'teamname'] = 'AZ Alkmaar'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Go Ahead Eagles', 'teamname'] = 'GO Ahead Eagles'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Heracles Almelo', 'teamname'] = 'Heracles'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Feyenoord Rotterdam', 'teamname'] = 'Feyenoord'\n",
    "sorare_data.loc[sorare_data['teamname'] =='PSV Eindhoven', 'teamname'] = 'PSV Eindhoven'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Fortuna Sittard', 'teamname'] = 'Fortuna Sittard'\n",
    "sorare_data.loc[sorare_data['teamname'] =='N.E.C. Nijmegen', 'teamname'] = 'NEC Nijmegen'\t\n",
    "sorare_data.loc[sorare_data['teamname'] =='Willem II', 'teamname'] = 'Willem II'\n",
    "sorare_data.loc[sorare_data['teamname'] =='AFC Ajax', 'teamname'] = 'Ajax'\n",
    "\n",
    "#also premier league\n",
    "sorare_data.loc[sorare_data['teamname'] =='Crystal Palace FC', 'teamname'] =  'Crystal Palace' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Arsenal FC', 'teamname'] = \t  'Arsenal' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Nottingham Forest FC' , 'teamname'] =\t       'Nottingham Forest'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Chelsea FC', 'teamname'] =\t       'Chelsea'\n",
    "sorare_data.loc[sorare_data['teamname'] =='AFC Bournemouth', 'teamname'] = \t  'Bournemouth' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Manchester United FC', 'teamname'] = 'Manchester United' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Fulham FC', 'teamname'] = 'Fulham'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Sheffield United FC' , 'teamname'] =\t  'Sheffield Utd' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Aston Villa FC', 'teamname'] =  'Aston Villa' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Newcastle United FC', 'teamname'] =\t  'Newcastle' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Tottenham Hotspur FC', 'teamname'] =  'Tottenham' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Brentford FC', 'teamname'] =  'Brentford' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Southampton FC'\t, 'teamname'] = 'Southampton'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Wolverhampton Wanderers FC', 'teamname'] =  'Wolves' \n",
    "sorare_data.loc[sorare_data['teamname'] == 'Burnley FC'\t, 'teamname'] =\t'Burnley'\n",
    "sorare_data.loc[sorare_data['teamname'] =='West Ham United FC', 'teamname'] = 'West Ham' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Brighton & Hove Albion FC', 'teamname'] = 'Brighton'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Leicester City FC'\t, 'teamname'] = 'Leicester'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Liverpool FC' , 'teamname'] = 'Liverpool' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Ipswich Town FC' , 'teamname'] =\t'Ipswich'\n",
    "sorare_data.loc[sorare_data['teamname'] =='Everton FC'\t, 'teamname'] =  'Everton' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Luton Town FC', 'teamname'] = 'Luton' \n",
    "sorare_data.loc[sorare_data['teamname'] =='Manchester City FC', 'teamname'] = 'Manchester City' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334b2ae-b914-4b11-9472-535c03ca7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge scores and games with eachother    \n",
    "final_file = pd.merge(sorare_data, total_df, how=\"left\", on=[\"Date\", \"teamname\"], indicator=True)   \n",
    "final_file['_merge'].value_counts()\n",
    "#The observations that do not merge are from before 2024 or different competition (for example national teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39428333-79d9-48e1-88b4-a5dddd4ab86f",
   "metadata": {},
   "source": [
    "# Create dataframe for goalkeepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07054c-340c-4da6-8f30-0cb378592e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply condition using loc for price classification\n",
    "keepers = final_file[final_file['position']==\"Goalkeeper\"].copy()\n",
    "\n",
    "#adjust the decesive scores\n",
    "values = [10, 20, 25, 10]\n",
    "\n",
    "#Based on their original decisive score and goals conceded, we adjust their decesive score\n",
    "decisive_conditions = [\n",
    "    (keepers['decisive'] ==5) & (keepers['opponent_goals']>2),\n",
    "    (keepers['decisive'] ==15) & (keepers['opponent_goals']>2),\n",
    "    (keepers['decisive'] ==35)& (keepers['opponent_goals']>2),\n",
    "    (keepers['decisive'] >59) & (keepers['opponent_goals']>2)\n",
    "]\n",
    "\n",
    "#calculate new score\n",
    "keepers['extra_decisive'] = np.select(decisive_conditions, values)\n",
    "keepers['new_so5']= keepers['so5score']+keepers['extra_decisive']\n",
    "keepers = keepers[keepers['_merge'] ==\"both\"]\n",
    "\n",
    "#Select subset\n",
    "keepers_v2=keepers[['opponent_elo_value', 'elo_value', 'new_so5', 'so5score', 'teamname', 'opponent_teamname', 'place']]\n",
    "\n",
    "#create variable with the average elo rating\n",
    "keepers_v2['avg_elo_value'] = keepers_v2.groupby(['teamname'])['elo_value'].transform('mean')\n",
    "#Calculate which quintile the team should be in\n",
    "keepers_v2['quintiles'] = pd.qcut(keepers_v2['avg_elo_value'], 5, labels=False)\n",
    "\n",
    "#calculate the average score before and after the scoiring matrix change\n",
    "keepers_v2['AVG_score_new'] = keepers_v2.groupby(['quintiles'])['new_so5'].transform('mean')\n",
    "keepers_v2['AVG_score'] = keepers_v2.groupby(['quintiles'])['so5score'].transform('mean')\n",
    "\n",
    "#Do this again but then per opposition quintiles\n",
    "keepers_v2['avg_elo_value_opp'] = keepers_v2.groupby(['opponent_teamname'])['opponent_elo_value'].transform('mean')\n",
    "#Calculate which quintile the team should be in\n",
    "keepers_v2['quintiles_opp'] = pd.qcut(keepers_v2['avg_elo_value_opp'], 5, labels=False)\n",
    "\n",
    "#calculate the average score before and after the scoiring matrix change\n",
    "keepers_v2['AVG_score_new_opp'] = keepers_v2.groupby(['quintiles_opp'])['new_so5'].transform('mean')\n",
    "keepers_v2['AVG_score_opp'] = keepers_v2.groupby(['quintiles_opp'])['so5score'].transform('mean')\n",
    "\n",
    "#deciles run from 0 to 4, thus add 1 for readability\n",
    "keepers_v2['quintiles'] = keepers_v2['quintiles']+1\n",
    "keepers_v2['quintiles_opp'] = keepers_v2['quintiles_opp']+1\n",
    "\n",
    "#create dataframes with one average value per decile\n",
    "keepers_def=keepers_v2.drop_duplicates('quintiles')\n",
    "keepers_def=keepers_def.sort_values('quintiles')\n",
    "\n",
    "keepers_opp_def=keepers_v2.drop_duplicates('quintiles_opp')\n",
    "keepers_opp_def=keepers_opp_def.sort_values('quintiles_opp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82103844-8d28-4b20-b7b0-633cfc585d28",
   "metadata": {},
   "source": [
    "# Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326b669-033e-47ae-9804-4350c0ec6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function the create figures\n",
    "def figures_gk(df, quintiles, scoring, scoring_new, name):\n",
    "    # Create side-by-side plots with shared y-axis\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    \n",
    "    # First barplot\n",
    "    sns.barplot(data=df, x=quintiles, y=scoring, ax=ax1)\n",
    "    ax1.set_title('With negative decisives')\n",
    "    ax1.set_xlabel('Quintiles')\n",
    "    ax1.set_ylabel('Average score within quintile')\n",
    "    ax1.set_xticklabels(['Relegation', 'Lower mid-table', 'Mid-table', 'Challengers', 'Elite'])\n",
    "\n",
    "    # Add value labels to each bar\n",
    "    for container in ax1.containers:\n",
    "        ax1.bar_label(container, fmt='%.0f', padding=3)\n",
    "    \n",
    "    # Second barplot\n",
    "    sns.barplot(data=df, x=quintiles, y=scoring_new, ax=ax2)\n",
    "    ax2.set_title('No negative decisives')\n",
    "    ax2.set_xlabel('Quintiles')\n",
    "    ax2.set_ylabel('')  # No label here since y-axis is shared\n",
    "    ax2.set_xticklabels(['Relegation', 'Lower mid-table', 'Mid-table', 'Challengers', 'Elite'])\n",
    "    \n",
    "    # Add value labels to each bar\n",
    "    for container in ax2.containers:\n",
    "        ax2.bar_label(container, fmt='%.0f', padding=3)\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"score_{name}.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94257d-9b1d-4f31-9a82-d73dcd767446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the the plots\n",
    "figures_gk(keepers_def, \"quintiles\", \"AVG_score\", \"AVG_score_new\", \"GK_quintiles_scores\")\n",
    "figures_gk(keepers_opp_def, \"quintiles_opp\", \"AVG_score_opp\", \"AVG_score_new_opp\", \"GK_quintiles_scores_opposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77918195-36b0-4b89-b6dc-3a05f296ea95",
   "metadata": {},
   "source": [
    "# Home and away analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623b7ae-e68a-4947-8c2f-102575172462",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers_v2_home = keepers_v2[keepers_v2['place']==\"home\"]\n",
    "keepers_v2_away = keepers_v2[keepers_v2['place']==\"away\"]\n",
    "\n",
    "#calculate the average score before and after the scoiring matrix change\n",
    "keepers_v2_home['AVG_score_new'] = keepers_v2_home.groupby(['quintiles'])['new_so5'].transform('mean')\n",
    "keepers_v2_home['AVG_score'] = keepers_v2_home.groupby(['quintiles'])['so5score'].transform('mean')\n",
    "\n",
    "#calculate the average score before and after the scoiring matrix change\n",
    "keepers_v2_away['AVG_score_new'] = keepers_v2_away.groupby(['quintiles'])['new_so5'].transform('mean')\n",
    "keepers_v2_away['AVG_score'] = keepers_v2_away.groupby(['quintiles'])['so5score'].transform('mean')\n",
    "\n",
    "#create dataframes with one average value per decile\n",
    "keepers_home_def=keepers_v2_home.drop_duplicates('quintiles')\n",
    "keepers_home_def=keepers_home_def.sort_values('quintiles')\n",
    "\n",
    "keepers_away_def=keepers_v2_away.drop_duplicates('quintiles')\n",
    "keepers_away_def=keepers_away_def.sort_values('quintiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce365aa6-2469-480c-90dc-d1f99db4c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the the plots\n",
    "# Create side-by-side plots with shared y-axis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    \n",
    "# First barplot\n",
    "sns.barplot(data=keepers_home_def, x=\"quintiles\", y=\"AVG_score_new\", ax=ax1)\n",
    "ax1.set_title('Home')\n",
    "ax1.set_xlabel('Quintiles')\n",
    "ax1.set_ylabel('Average score within quintile')\n",
    "ax1.set_xticklabels(['Relegation', 'Lower mid-table', 'Mid-table', 'Challengers', 'Elite'])\n",
    "\n",
    "# Add value labels to each bar\n",
    "for container in ax1.containers:\n",
    "    ax1.bar_label(container, fmt='%.0f', padding=3)\n",
    "    \n",
    "# Second barplot\n",
    "sns.barplot(data=keepers_away_def, x=\"quintiles\", y=\"AVG_score_new\", ax=ax2)\n",
    "ax2.set_title('Away')\n",
    "ax2.set_xlabel('Quintiles')\n",
    "ax2.set_ylabel('')  # No label here since y-axis is shared\n",
    "ax2.set_xticklabels(['Relegation', 'Lower mid-table', 'Mid-table', 'Challengers', 'Elite'])\n",
    "    \n",
    "# Add value labels to each bar\n",
    "for container in ax2.containers:\n",
    "    ax2.bar_label(container, fmt='%.0f', padding=3)\n",
    "    \n",
    "    # Improve layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"Home_and_away_results.png\", dpi=300, bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
